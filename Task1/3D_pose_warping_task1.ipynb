{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3D_pose_warping_task1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KL1bBnWWVm7"
      },
      "source": [
        "# Dataset exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feFLBN8Aenvu"
      },
      "source": [
        "\n",
        "*   Explore the **In-shop Clothes Retrieval Benchmark** of the **DeepFashion** dataset\n",
        "http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion/InShopRetrieval.html\n",
        "*   Import the dataset in `Google Colab` instead of downloading the whole dataset locally\n",
        "*   Visualize some samples from the dataset\n",
        "*   Look for variations and correlations in the dataset\n",
        "*   Use the `matplotlib` and `seaborn` library to visualize data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4rDRlEtThni"
      },
      "source": [
        "# Add code cells in this section"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7TM8utGWfyl"
      },
      "source": [
        "# ResNET Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws2Z2KTVUb16"
      },
      "source": [
        "\n",
        "\n",
        "*   Read about **ResNET** architecture and advantage of residual blocks\n",
        "*   Build a simple 6-layer ConvNET and train it on **CIFAR-10** dataset\n",
        "*   Introduce residual blocks in the above model and compare the results \n",
        "*   Use the `tensorflow` library to import ResNET model with imgaenet weights\n",
        "*   Change some parameters and document the results\n",
        "*   Visualize the output of some layers and add/delete layers to see the effect of individual layers on the model accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07WvlRnwjVcO"
      },
      "source": [
        "# I am trying using keras \n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "#model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "#model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(10), activation=' softmax')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKInCk4WTo2r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "78661b63-663a-4409-edb2-708eb21db5fb"
      },
      "source": [
        "# Add code cells in this section\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "#from tensorflow.examples.tutorials.mnist import input_data\n",
        "# load dataset\n",
        "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\n",
        "batch_size = 128\n",
        "test_size = 256\n",
        "\n",
        "def init_weights(shape):\n",
        "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
        "\n",
        "def model(X, w, w2, w3, w4, w5, w6, w_o, p_keep_conv, p_keep_hidden):\n",
        "    l1 = tf.nn.relu(tf.nn.conv2d(X, w,                       # l1a shape=(?, 28, 28, 32)\n",
        "                        strides=[1, 1, 1, 1], padding='SAME'))\n",
        "    #l1 = tf.nn.max_pool(l1a, ksize=[1, 2, 2, 1],              # l1 shape=(?, 28, 28, 32)\n",
        "                        #strides=[1, 2, 2, 1], padding='SAME')\n",
        "    l1 = tf.nn.dropout(l1, p_keep_conv)\n",
        "\n",
        "    l2a = tf.nn.relu(tf.nn.conv2d(l1, w2,                     # l2a shape=(?, 28, 28, 64)\n",
        "                        strides=[1, 1, 1, 1], padding='SAME'))\n",
        "    l2 = tf.nn.max_pool(l2a, ksize=[1, 2, 2, 1],              # l2 shape=(?, 14, 14, 64)\n",
        "                        strides=[1, 2, 2, 1], padding='SAME')\n",
        "    l2 = tf.nn.dropout(l2, p_keep_conv)\n",
        "\n",
        "    l3 = tf.nn.relu(tf.nn.conv2d(l2, w3,                     # l3a shape=(?, 7, 7, 128)\n",
        "                        strides=[1, 1, 1, 1], padding='SAME'))\n",
        "    #l3 = tf.nn.max_pool(l3a, ksize=[1, 2, 2, 1],              # l3 shape=(?, 7, 7, 128)\n",
        "                        #strides=[1, 2, 2, 1], padding='SAME')\n",
        "    l3 = tf.nn.dropout(l3, p_keep_conv)\n",
        "\n",
        "    l4a = tf.nn.relu(tf.nn.conv2d(l3, w4,                     # l4a shape=(?, 7, 7, 256)\n",
        "                        strides=[1, 1, 1, 1], padding='SAME'))\n",
        "    l4 = tf.nn.max_pool(l4a, ksize=[1, 2, 2, 1],              # l4 shape=(?, 4, 4, 256)\n",
        "                        strides=[1, 2, 2, 1], padding='SAME')\n",
        "    l4 = tf.nn.dropout(l4, p_keep_conv)\n",
        "\n",
        "    l5 = tf.nn.relu(tf.nn.conv2d(l4, w5,                     # l5a shape=(?, 4, 4, 512)\n",
        "                        strides=[1, 1, 1, 1], padding='SAME'))\n",
        "    #l5 = tf.nn.max_pool(l5a, ksize=[1, 2, 2, 1],              # l5 shape=(?, 4, 4, 512)\n",
        "                        #strides=[1, 2, 2, 1], padding='SAME')\n",
        "    l5 = tf.nn.dropout(l5, p_keep_conv)\n",
        "\n",
        "\n",
        "\n",
        "    l5 = tf.reshape(l5, [-1, w6.get_shape().as_list()[0]])    # reshape to (?, 512*4*4)\n",
        "    l5 = tf.nn.dropout(l5, p_keep_conv)\n",
        "\n",
        "    l6 = tf.nn.relu(tf.matmul(l5, w6))\n",
        "    l6 = tf.nn.dropout(l6, p_keep_hidden)\n",
        "\n",
        "    pyx = tf.matmul(l6, w_o)\n",
        "    return pyx\n",
        "\n",
        "# load dataset\n",
        "(trainX_c, trainY), (testX_c, testY) = cifar10.load_data()\n",
        "\n",
        "#trainX = np.mean(trainX_c, axis=2)\n",
        "#testX = np.mean(testX_c, axis=2)\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "trainX, testX = trainX / 255.0, testX / 255.0\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, 28, 28, 1])\n",
        "Y = tf.placeholder(\"float\", [None, 10])\n",
        "\n",
        "w = init_weights([3, 3, 1, 32])       # 3x3x1 conv, 32 outputs\n",
        "w2 = init_weights([3, 3, 32, 64])     # 3x3x32 conv, 64 outputs\n",
        "w3 = init_weights([3, 3, 64, 128])    # 3x3x32 conv, 128 outputs\n",
        "w4 = init_weights([3, 3, 128, 256])   # 3x3x32 conv, 256 outputs\n",
        "w5 = init_weights([3, 3, 256, 512])   # 3x3x32 conv, 512 outputs\n",
        "w6 = init_weights([512 * 4 * 4, 625]) # FC 512 * 4 * 4 inputs, 625 outputs\n",
        "w_o = init_weights([625, 10])         # FC 625 inputs, 10 outputs (labels)\n",
        "\n",
        "p_keep_conv = tf.placeholder(\"float\")\n",
        "p_keep_hidden = tf.placeholder(\"float\")\n",
        "py_x = model(X, w, w2, w3, w4, w5, w6, w_o, p_keep_conv, p_keep_hidden)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=Y))\n",
        "train_op = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
        "predict_op = tf.argmax(py_x, 1)\n",
        "\n",
        "\n",
        "# Launch the graph in a session\n",
        "with tf.Session() as sess:\n",
        "    # you need to initialize all variables\n",
        "    tf.global_variables_initializer().run()\n",
        "\n",
        "    for i in range(100):\n",
        "        training_batch = zip(range(0, len(trainX), batch_size),\n",
        "                             range(batch_size, len(trainX)+1, batch_size))\n",
        "        for start, end in training_batch:\n",
        "            sess.run(train_op, feed_dict={X: trainX[start:end], Y: trainY[start:end],\n",
        "                                          p_keep_conv: 0.8, p_keep_hidden: 0.5})\n",
        "\n",
        "        test_indices = np.arange(len(testX)) # Get A Test Batch\n",
        "        np.random.shuffle(test_indices)\n",
        "        test_indices = test_indices[0:test_size]\n",
        "\n",
        "        print(i, np.mean(np.argmax(testY[test_indices], axis=1) ==\n",
        "                         sess.run(predict_op, feed_dict={X: testX[test_indices],\n",
        "                                                         Y: testY[test_indices],\n",
        "                                                         p_keep_conv: 1.0,\n",
        "                                                         p_keep_hidden: 1.0})))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-17e3f741ceed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             sess.run(train_op, feed_dict={X: trainX[start:end], Y: trainY[start:end],\n\u001b[0;32m---> 96\u001b[0;31m                                           p_keep_conv: 0.8, p_keep_hidden: 0.5})\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mtest_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Get A Test Batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1157\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (128, 32, 3) for Tensor 'Placeholder_24:0', which has shape '(?, 28, 28, 1)'"
          ]
        }
      ]
    }
  ]
}